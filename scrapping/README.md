# ğŸ¤– Intelligent Web Scraper (TypeScript)

**Autonomous Website Exploration with Detailed Logging & Multiple Screenshots**

## âœ¨ Features

- **ğŸ§  Intelligent Exploration**: Step-by-step autonomous website navigation
- **ğŸ“¸ Multiple Screenshots**: Captures screenshots at every action step
- **ğŸ“ Detailed Logging**: Creates individual log files for each step + master log
- **ğŸ”„ Dynamic Interaction**: Clicks links, navigates pages, extracts data
- **ğŸ“Š Structured Data**: Exports comprehensive JSON results
- **ğŸ¯ Goal-Oriented**: Follows a systematic exploration pattern

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- **Google Gemini API key** (required for LLM automation)

### Installation

```bash
# Install dependencies
npm install

# Setup environment
cp .env.example .env
# Edit .env with your Google API key
```

### Usage

```bash
# Run the scraper
npm test

# Or with dev mode (auto-reload)
npm run dev
```

## ğŸ¯ How It Works

### Exploration Flow
The scraper follows this exact pattern:

1. **ğŸŒ Initialize Browser** - Set up Stagehand automation
2. **ğŸ”— Navigate** - Go to target URL + take screenshot
3. **ğŸ‘€ Observe** - Analyze page structure and navigation
4. **ğŸ“Š Extract** - Get basic page information and content
5. **ğŸ”„ Interact** - Click navigation links (About/Services)
6. **ğŸ“¸ Screenshot** - Capture multiple page views
7. **ğŸ“Š Secondary Extract** - Get information from new page
8. **ğŸ”™ Navigate Back** - Return to home page
9. **ğŸ“Š Final Extract** - Comprehensive data extraction

### Screenshots Captured
- **Navigation screenshots** - After each page navigation
- **Action result screenshots** - After clicking/interacting
- **Full page screenshots** - Complete page capture
- **Viewport screenshots** - Above-the-fold content
- **Multiple per step** - Different views of same action

### Log Files Created
```
analysis/
â””â”€â”€ domain_name_timestamp/
    â”œâ”€â”€ step_01_initialize.json
    â”œâ”€â”€ step_02_browser_init.json
    â”œâ”€â”€ step_03_navigate.json
    â”œâ”€â”€ step_04_page_observe.json
    â”œâ”€â”€ step_05_page_extract.json
    â”œâ”€â”€ step_06_page_act.json
    â”œâ”€â”€ step_07_take_screenshot.json
    â”œâ”€â”€ step_08_page_extract.json
    â”œâ”€â”€ step_09_page_act.json
    â”œâ”€â”€ step_10_page_extract.json
    â”œâ”€â”€ master_log.json
    â”œâ”€â”€ session_metadata.json
    â””â”€â”€ complete_session_log.json
```

## ğŸ“Š Data Structure

```typescript
interface ScrapingResult {
  success: boolean;
  url: string;
  totalSteps: number;
  explorationSteps: ExplorationStep[];
  screenshots: Screenshot[];
  extractedData: {
    observations: any[];
    extractions: any[];
    actions: any[];
    pageInfo: any;
  };
  processingTime: number;
  timestamp: string;
  sessionId: string;
}
```

### Example Output
```json
{
  "success": true,
  "url": "https://profit.co",
  "totalSteps": 7,
  "explorationSteps": [
    {
      "step": 1,
      "action": { "action": "page_observe", "instruction": "Analyze page structure" },
      "success": true,
      "data": { "observation": {...}, "pageUrl": "..." },
      "screenshots": []
    }
  ],
  "screenshots": [
    {
      "filename": "step_02_navigate_2025-06-25T10-30-45-123Z.png",
      "path": "screenshots/domain_timestamp/...",
      "step": 2,
      "action": "navigate",
      "timestamp": "2025-06-25T10:30:45.123Z"
    }
  ],
  "extractedData": {
    "observations": [...],
    "extractions": [...],
    "actions": [...],
    "pageInfo": {...}
  },
  "processingTime": 45000,
  "sessionId": "profit_co_2025-06-25T10-30-45Z"
}
```

## ğŸ”§ Configuration

### Change Target URL
Edit `src/index.ts`:
```typescript
const testUrl = 'https://your-target-website.com';
const objective = 'Your exploration objective here';
```

### Environment Variables
Create `.env`:
```bash
GOOGLE_API_KEY=your_google_api_key_here
```

## ğŸ“ File Structure

```
src/
â”œâ”€â”€ types/
â”‚   â””â”€â”€ index.ts              # TypeScript interfaces
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logger.ts            # Winston logging setup  
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ IntelligentScraper.ts   # Main scraper engine
â”‚   â”œâ”€â”€ SessionLogger.ts        # Step-by-step logging
â”‚   â””â”€â”€ ScreenshotManager.ts    # Screenshot handling
â””â”€â”€ index.ts                 # Entry point

Generated Output:
â”œâ”€â”€ analysis/                # Step-by-step logs
â”œâ”€â”€ screenshots/             # Captured images  
â”œâ”€â”€ data/                   # Final JSON results
â””â”€â”€ logs/                   # System logs
```

## ğŸ¯ Action Types

- **`page_observe`** - Analyze page structure, find navigation elements
- **`page_act`** - Interact with page (click links, navigate)
- **`page_extract`** - Extract data (titles, content, contact info)
- **`take_screenshot`** - Capture visual state of page

## ğŸ“¸ Screenshot Organization

Screenshots are organized by session and step:
```
screenshots/
â””â”€â”€ profit_co_2025-06-25T10-30-45Z/
    â”œâ”€â”€ step_02_navigate_2025-06-25T10-30-45-123Z.png
    â”œâ”€â”€ step_06_action_result_2025-06-25T10-30-47-456Z.png
    â”œâ”€â”€ step_07_full_page_2025-06-25T10-30-48-789Z.png
    â”œâ”€â”€ step_07_viewport_2025-06-25T10-30-49-012Z.png
    â””â”€â”€ screenshot_manifest.json
```

## ğŸ” Example Console Output

```bash
ğŸš€ Starting Intelligent Web Scraper
ğŸ¯ Testing with URL: https://profit.co
ğŸš€ Session started: profit_co_2025-06-25T10-30-45Z
ğŸŒ Initializing browser...
âœ… Browser initialized successfully
ğŸ”— Navigating to: https://profit.co
âœ… Successfully navigated to https://profit.co
ğŸ”„ Step 2: page_observe - Analyze the current page structure
âœ… Step 2: page_observe - Analyze the current page structure (1250ms)
ğŸ”„ Step 3: page_extract - Extract basic page information
âœ… Step 3: page_extract - Extract basic page information (890ms)
ğŸ”„ Step 4: page_act - Look for and click on About or Services navigation link
âœ… Step 4: page_act - Look for and click on About or Services navigation link (2100ms) | Screenshots: 1
ğŸ”„ Step 5: take_screenshot - Capture multiple screenshots
ğŸ“¸ 2 screenshots saved for step 5
âœ… Step 5: take_screenshot - Capture multiple screenshots (1450ms) | Screenshots: 2
âœ… Scraping completed successfully!
ğŸ“Š Results:
   â€¢ Total Steps: 7
   â€¢ Screenshots: 8
   â€¢ Processing Time: 15230ms
   â€¢ Session ID: profit_co_2025-06-25T10-30-45Z
```

## ğŸ›  Development

```bash
# Build TypeScript
npm run build

# Run with auto-reload
npm run dev

# Direct execution
npm start
```

## ğŸš€ Get Started

1. **Get Google Gemini API key** from [Google AI Studio](https://makersuite.google.com/app/apikey)
2. **Set environment variables** in `.env`
3. **Run the scraper**: `npm test`

That's it! The system will autonomously explore the website and create detailed logs and screenshots of every step. ğŸ‰